#V1.0 This version is made with tensor flow library

import pandas as pd
import numpy as np
import os

import tensorflow as tf
from tensorflow import keras

import matplotlib.pyplot as plt

from transformers import BertModel, BertTokenizer
from sklearn.model_selection import train_test_split

from textwrap import wrap

#DEFINICION DE CONSTANTES
CKPT_PATH = "./Bert_Model.ckpt"
DATASET_PATH = "../DataSets/News_DataSet/News6K.csv"
RANDOM_SEED = 42
MAX_LEN = 200
BATCH_SIZE = 16
EPOCHS = 10

PRETRAINED_BERT_MODEL = 'bert-base-cased'
BERT_HIDDENS = 768
NCLASES = 2

np.random.seed(RANDOM_SEED)

if os.path.exists(DATASE

tokenizer = BertTokenizer.from_pretrained(PRETRAINED_BERT_MODEL)
bert = BertModel.from_pretrained(PRETRAINED_BERT_MODEL)

#SAMPLE DEL PROCESO DE TOKENIZACIÓN
sample_txt = "Places to visit with your son"
tokens = tokenizer.tokenize(sample_txt)
token_ids = tokenizer.convert_tokens_to_ids(tokens)

print(
	'Frase: ', sample_txt,
	'\nTokens: ', tokens,
	'\nToken_IDS: ', token_ids
)

encoder = tokenizer.encode_plus(
    sample_txt,
    max_length = 15,
    truncation = True,
    add_special_tokens = True,
    return_token_type_ids = False,
    padding = 'max_length',
    return_attention_mask = True,
    return_tensors = 'pt' 
)

print(
	encoder.keys(),
	encoder['input_ids']
)

#FUNCION PARA CREAR EL MODELO TENSOR FLOW DOS CAPAS, HIDDEN CON TAMAÑO BERT_NHIDDENS y CAPA DE SALIDA TAMAÑO NCLASES
def create_model():
	model = keras.Sequential([
		keras.layers.Dense(BERT_NHIDDENS, activation='relu'),
		keras.layers.Dense(NCLASES, activation='softmax')
	])

	model.compile(
		optimizer='adam',
		loss='parse_categorical_crossentropy',
		metrics=['accuracy'],
	)

	return model




outputs, cls_output = bert(encoder['input_ids'], encoder['attention_mask'], return_dict=False)

print(cls_output)
