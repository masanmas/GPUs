{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"News_Model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1rATTKS2rKIZlAoTof5ezEUEpMpX_j1Rt","authorship_tag":"ABX9TyNBsmDMhRpUbUBbfBPaaTui"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"UkjVnwUKFkk7"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-w1VkjkFdXJ"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n"," \n","import torch\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n","from sklearn.model_selection import train_test_split\n"," \n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKQdBZ89NKra"},"source":["#DEFINITION OF CONSTANTS\n","FILE_PATH = '/content/drive/MyDrive/GPUs/Bert/DataSet/News_DataSet/11_CLASSES/MoreThan5k.csv'\n","RANDOM_SEED = 42\n","MAX_LEN = 200\n","BATCH_SIZE = 16\n","NCLASSES = 11\n","PRETRAINED_BERT_MODEL = 'bert-base-cased'\n","NHIDDENS = 768\n","PATIENCE = 3\n","NAME_CLASSES = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3SylIcpNOCR"},"source":["#SETTING RANDOM VARIABLES\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","\n","#READING FILE\n","df = pd.read_csv(FILE_PATH)\n","\n","#Other variables\n","device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_BERT_MODEL)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"medwolLFNaAX"},"source":["class IMDBdataset(Dataset):\n","    \n","    def __init__(self, reviews, labels, tokenizer, max_len):\n","        self.reviews = reviews\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.reviews)\n","\n","    def __getitem__(self, item):\n","        review = str(self.reviews[item])\n","        label = self.labels[item]\n","\n","        encoding = tokenizer.encode_plus(\n","            review,\n","            max_length = self.max_len,\n","            truncation = True,\n","            add_special_tokens = True,\n","            return_token_type_ids = False,\n","            padding = 'max_length',\n","            return_attention_mask = True,\n","            return_tensors = 'pt'\n","        )\n","\n","        return {\n","            'review': review,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        } \n","\n","def data_loader(df, tokenizer, max_len, batch_size):\n","    dataset = IMDBdataset(\n","        reviews = df.headline.to_numpy(),\n","        labels = df.label.to_numpy(),\n","        tokenizer = tokenizer,\n","        max_len = MAX_LEN\n","    )\n","\n","    return DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=2)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-EylPiHOB8K"},"source":["df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n","df_validation, df_test = train_test_split(df_test, test_size=0.5, random_state=42)\n","\n","#Loader \n","train_data_loader = data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n","test_data_loader = data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n","validation_data_loader = data_loader(df_validation, tokenizer, MAX_LEN, BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxYPHxcXOkDB"},"source":["class BERTArticleClassificator(nn.Module):\n","\n","    def __init__(self, numClases):\n","        super(BERTArticleClassificator, self).__init__()\n","        self.bert = BertModel.from_pretrained(PRETRAINED_BERT_MODEL)\n","        self.drop = nn.Dropout(p=0.3)\n","        self.linear = nn.Linear(self.bert.config.hidden_size, NCLASSES)\n","    \n","    def forward(self, input_ids, attention_mask):\n","        outputs, cls_output = self.bert(\n","            input_ids = input_ids,\n","            attention_mask = attention_mask,\n","            return_dict = False\n","        )\n","\n","        drop_out = self.drop(cls_output)\n","        output = self.linear(drop_out)\n","\n","        return output\n","\n","model = BERTArticleClassificator(NCLASSES)\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QjzEtiygOzLO"},"source":["EPOCHS = 25 #Iteraciones de entrenamiento\n","optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n","total_steps = len(train_data_loader) * EPOCHS #Batch_Size * EPOCHS\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps = 0,\n","    num_training_steps = total_steps\n",")\n","\n","loss_fn = nn.CrossEntropyLoss().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WaDjABdqO39Y"},"source":["#Iteración entrenamiento\n","def train_model(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n","    model = model.train()\n","    losses = []\n","    correct_predictions = 0\n","    for batch in data_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['label'].to(device)\n","        output = model(input_ids=input_ids, attention_mask=attention_mask)\n","        _, preds = torch.max(output, dim=1)\n","        loss = loss_fn(output, labels)\n","        correct_predictions += torch.sum(preds == labels)\n","        losses.append(loss.item())\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","\n","    return correct_predictions.double()/n_examples, np.mean(losses)\n","\n","def eval_model(model, data_loader, loss_fn, device, n_examples):\n","    model = model.eval()\n","    losses = []\n","    correct_predictions = 0\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['label'].to(device)\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            _, preds = torch.max(outputs, dim=1)\n","            loss = loss_fn(outputs, labels)\n","            correct_predictions += torch.sum(preds == labels)\n","            losses.append(loss.item())\n","\n","    return correct_predictions.double()/n_examples, np.mean(losses)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"grbeYICmFZvj","outputId":"0e29581d-bf63-4c6a-dc5c-d849a3682557"},"source":["test_acc_max, test_acc_index = 0, 0\n","\n","for epoch in range(EPOCHS):\n","    print('Epoch {} de {}'.format(epoch+1, EPOCHS))\n","    print('-'*10)\n","    train_acc, train_loss = train_model(\n","          model, train_data_loader, loss_fn, optimizer, device, scheduler, len(df_train)\n","    )\n","    \n","    test_acc, test_loss = eval_model(\n","          model, test_data_loader, loss_fn, device, len(df_test)\n","    )\n","    \n","    print('Entrenamiento: Loss: {}, accuracy: {}'.format(train_loss, train_acc))\n","    print('Validación: Loss: {}, accuracy: {}'.format(test_loss, test_acc))\n","    print('')\n","\n","    if test_acc > test_acc_max:\n","      test_acc_max = test_acc\n","      test_acc_index = epoch\n","    \n","    elif epoch - test_acc_index >= PATIENCE:\n","      print('STOP AT {} EPOCH OBTAINED MAX {} FROM EPOCH {}'.format(epoch, train_acc_max, train_acc_index))\n","      break\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1 de 25\n","----------\n","Entrenamiento: Loss: 0.9972491566430438, accuracy: 0.6722954545454545\n","Validación: Loss: 0.7743304917198974, accuracy: 0.744\n","\n","Epoch 2 de 25\n","----------\n","Entrenamiento: Loss: 0.6021072606918487, accuracy: 0.8010227272727273\n","Validación: Loss: 0.7676195424526583, accuracy: 0.7587272727272727\n","\n","Epoch 3 de 25\n","----------\n","Entrenamiento: Loss: 0.39885417728159916, accuracy: 0.87\n","Validación: Loss: 0.8949490250034128, accuracy: 0.7516363636363635\n","\n","Epoch 4 de 25\n","----------\n","Entrenamiento: Loss: 0.26775292825394054, accuracy: 0.9156590909090908\n","Validación: Loss: 1.062461182442602, accuracy: 0.75\n","\n","Epoch 5 de 25\n","----------\n","Entrenamiento: Loss: 0.19064185138533568, accuracy: 0.9445681818181818\n","Validación: Loss: 1.2944797664010346, accuracy: 0.7567272727272727\n","\n","Epoch 6 de 25\n","----------\n","Entrenamiento: Loss: 0.14389663414576684, accuracy: 0.9601363636363636\n","Validación: Loss: 1.5306980836693858, accuracy: 0.7481818181818182\n","\n","Epoch 7 de 25\n","----------\n","Entrenamiento: Loss: 0.12309993135869313, accuracy: 0.9682045454545454\n","Validación: Loss: 1.639150477891658, accuracy: 0.7501818181818182\n","\n","Epoch 8 de 25\n","----------\n","Entrenamiento: Loss: 0.0910861039255661, accuracy: 0.9766136363636363\n","Validación: Loss: 1.7730336272265006, accuracy: 0.7525454545454545\n","\n","Epoch 9 de 25\n","----------\n"],"name":"stdout"}]}]}